{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertTokenizerFast, BertConfig, AutoTokenizer, RobertaTokenizer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'seyonec/PubChem10M_SMILES_BPE_180k'\n",
    "MODEL_PATH = './model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokenizer():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(f'{MODEL_NAME}', normalization=True, caeche_dir='./cache')\n",
    "    tokenizer.save_pretrained(f'{MODEL_PATH}')\n",
    "    print(f'tokenizer object load & save......[{MODEL_NAME}]')\n",
    "\n",
    "    example = \"Cn1c(=O)c2c(ncn2C)n(C)c1=O\"\n",
    "    tokens = tokenizer(example) # example\n",
    "    tokens_ = tokenizer.tokenize(example) # example\n",
    "    print(tokens)\n",
    "    print(tokens_)\n",
    "    \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_to = RobertaTokenizer(vocab_file='./model/vocab.json', merges_file='./model/merges.txt', do_lower_case=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast(vocab_file='./model/vocab.txt', do_lower_case=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 361, 111, 132, 150, 112, 100, 111, 100, 112, 138, 111, 132, 150, 112, 149, 111, 138, 112, 100, 132, 150, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('CC(=O)Nc1ccc2c(c1)C(=O)N(C)C2=O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 262, 263, 51, 13, 278, 21, 264, 22, 71, 12, 71, 21, 13, 39, 263, 51, 13, 50, 12, 39, 13, 39, 22, 33, 51, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_to('CC(=O)Nc1ccc2c(c1)C(=O)N(C)C2=O')\n",
    "os.makedirs('./model', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = BertConfig(vocab_size=a_to.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7924"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SmBert(nn.Module):\n",
    "    def __init__(self, bert_config, tokenizer):\n",
    "        self.bert = BertModel(bert_config)\n",
    "        self.cls = BertOnlyMLMHead(config)\n",
    "        self.loss_fct = CrossEntropyLoss()\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, labels):\n",
    "        outputs = self.bert(input_ids, attention_mask, token_type_ids)\n",
    "        sequence_output = outputs[0]\n",
    "        prediction_scores = self.cls(sequence_output)\n",
    "        loss = self.loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sider_smiles.json', 'w') as f:\n",
    "    json.dump(smiles_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sider_names['cid'].replace('CID\\d', '', regex=True, inplace=True)\n",
    "sider_names['cid'] = sider_names['cid'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1430/1430 [24:48<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "sider_smiles = []\n",
    "\n",
    "for i, row in tqdm(sider_names.iterrows(), total=len(sider_names)):\n",
    "    try:\n",
    "        compound = pcp.Compound.from_cid(row[\"cid\"])\n",
    "        sider_smiles.append(\n",
    "            {\"cid\": row[\"cid\"], \"name\": row[\"name\"], \"smiles\": compound.isomeric_smiles},\n",
    "        )\n",
    "    except:\n",
    "        print(\"Error: \", row[\"cid\"], row[\"name\"])\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sider_smiles_df = pandas.DataFrame(sider_smiles)\n",
    "sider_smiles_df.to_csv(\"./data/sider_smiles.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bca2adbe3e527dfd8814b6bec6444f0f97c0b63f3a6c65c1c886a1622b466f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
